spec:
  container:
  - name: controller
    image: sfengineering-xaccounttest3.registry.snowflakecomputing.com/testdb/public/my_repo/images:llama2-hf-chat
    env:
      SYNC_DIR: /tmp/sync
    command:
      - ./exec/controller.sh
    volumeMounts:
      - name: sync
        mountPath: /tmp/sync
  - name: model-worker
    image: sfengineering-xaccounttest3.registry.snowflakecomputing.com/testdb/public/my_repo/images:llama2-hf-chat
    env:
      HUGGING_FACE_HUB_TOKEN: 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
      SYNC_DIR: /tmp/sync
    command:
      - ./exec/model_worker.sh
    volumeMounts:
      - name: sync
        mountPath: /tmp/sync
    resources:
        limits:
          nvidia.com/gpu: 1
        requests:
          nvidia.com/gpu: 1
  - name: gradio-ui
    image: sfengineering-xaccounttest3.registry.snowflakecomputing.com/testdb/public/my_repo/images:llama2-hf-chat
    env:
      SYNC_DIR: /tmp/sync
    command:
      - ./exec/gradio_ui.sh
    volumeMounts:
      - name: sync
        mountPath: /tmp/sync
  volumes:
  - name: sync
    source: local
  endpoint:
  - name: service
    port: 7860
    public: true

